{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PySDS Week 02 Day 02 v.1 - Exercise - File Types and Text Processing I**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we will be doing some example regular expressions (yay), and some dataframe manipulation. Recall that we used the Canada wikipedia page as an example. Below is some code that you can use to pull in a Wikipedia page as data. Today, you will be asked to read in several pages, compare them on a number of features in a dataframe and report on what you found.  Below is the code that you can use to download a Wikipedia page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<id>864288365</id>\n"
     ]
    }
   ],
   "source": [
    "import urllib, urllib.request\n",
    "import bs4 \n",
    "# You can set this Wikipage to be any string that has a wikipedia page.\n",
    "\n",
    "def getWikiPage(page=\"United Kingdom\"): \n",
    "    '''Returns the XML found using special export of a Wikipedia page.'''\n",
    "    \n",
    "    # Here we use urllib.parse.quote to turn spaces and special characters into\n",
    "    # the characters needed for an html string. So for example spaces become %20\n",
    "\n",
    "    URL = \"http://en.wikipedia.org/wiki/Special:Export/%s\" % urllib.parse.quote(page)\n",
    "\n",
    "#     print(URL,\"\\n\") # commented out as not necessary for later tasks\n",
    "\n",
    "    req = urllib.request.Request( URL, headers={'User-Agent': 'OII SDS class 2018.1/Hogan'})\n",
    "    infile = urllib.request.urlopen(req)\n",
    "\n",
    "    return infile.read()\n",
    "\n",
    "# Testing\n",
    "data = getWikiPage()\n",
    "soup = bs4.BeautifulSoup(data.decode('utf8'), \"lxml\")\n",
    "print(soup.mediawiki.page.revision.id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United Kingdom\n",
      "Canada\n",
      "Swaziland\n",
      "Indonesia\n",
      "Suriname\n",
      "Bhutan\n",
      "Latvia\n",
      "Madagascar\n",
      "Yemen\n",
      "Brazil\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wikilinks</th>\n",
       "      <th>OuterLinks</th>\n",
       "      <th>U_Wikilinks</th>\n",
       "      <th>U_OuterLinks</th>\n",
       "      <th>PageLength</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>United Kingdom</th>\n",
       "      <td>1631</td>\n",
       "      <td>656</td>\n",
       "      <td>1469</td>\n",
       "      <td>610</td>\n",
       "      <td>325644</td>\n",
       "      <td>63181775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Canada</th>\n",
       "      <td>950</td>\n",
       "      <td>607</td>\n",
       "      <td>883</td>\n",
       "      <td>565</td>\n",
       "      <td>234879</td>\n",
       "      <td>37067011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Swaziland</th>\n",
       "      <td>322</td>\n",
       "      <td>120</td>\n",
       "      <td>258</td>\n",
       "      <td>115</td>\n",
       "      <td>81842</td>\n",
       "      <td>1093238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indonesia</th>\n",
       "      <td>900</td>\n",
       "      <td>379</td>\n",
       "      <td>789</td>\n",
       "      <td>375</td>\n",
       "      <td>192566</td>\n",
       "      <td>237641326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Suriname</th>\n",
       "      <td>599</td>\n",
       "      <td>99</td>\n",
       "      <td>518</td>\n",
       "      <td>91</td>\n",
       "      <td>87635</td>\n",
       "      <td>541638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bhutan</th>\n",
       "      <td>660</td>\n",
       "      <td>189</td>\n",
       "      <td>536</td>\n",
       "      <td>186</td>\n",
       "      <td>124736</td>\n",
       "      <td>634982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Latvia</th>\n",
       "      <td>918</td>\n",
       "      <td>258</td>\n",
       "      <td>730</td>\n",
       "      <td>241</td>\n",
       "      <td>162347</td>\n",
       "      <td>1925800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Madagascar</th>\n",
       "      <td>606</td>\n",
       "      <td>220</td>\n",
       "      <td>509</td>\n",
       "      <td>214</td>\n",
       "      <td>167082</td>\n",
       "      <td>12238914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yemen</th>\n",
       "      <td>923</td>\n",
       "      <td>206</td>\n",
       "      <td>775</td>\n",
       "      <td>194</td>\n",
       "      <td>207542</td>\n",
       "      <td>19685000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brazil</th>\n",
       "      <td>1311</td>\n",
       "      <td>402</td>\n",
       "      <td>1154</td>\n",
       "      <td>378</td>\n",
       "      <td>242077</td>\n",
       "      <td>210147125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Wikilinks OuterLinks U_Wikilinks U_OuterLinks PageLength  \\\n",
       "United Kingdom      1631        656        1469          610     325644   \n",
       "Canada               950        607         883          565     234879   \n",
       "Swaziland            322        120         258          115      81842   \n",
       "Indonesia            900        379         789          375     192566   \n",
       "Suriname             599         99         518           91      87635   \n",
       "Bhutan               660        189         536          186     124736   \n",
       "Latvia               918        258         730          241     162347   \n",
       "Madagascar           606        220         509          214     167082   \n",
       "Yemen                923        206         775          194     207542   \n",
       "Brazil              1311        402        1154          378     242077   \n",
       "\n",
       "               Population  \n",
       "United Kingdom   63181775  \n",
       "Canada           37067011  \n",
       "Swaziland         1093238  \n",
       "Indonesia       237641326  \n",
       "Suriname           541638  \n",
       "Bhutan             634982  \n",
       "Latvia            1925800  \n",
       "Madagascar       12238914  \n",
       "Yemen            19685000  \n",
       "Brazil          210147125  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Sorted by Wikilinks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "United Kingdom    1631\n",
       "Brazil            1311\n",
       "Canada             950\n",
       "Yemen              923\n",
       "Latvia             918\n",
       "Indonesia          900\n",
       "Bhutan             660\n",
       "Madagascar         606\n",
       "Suriname           599\n",
       "Swaziland          322\n",
       "Name: Wikilinks, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Sorted by OuterLinks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "United Kingdom    656\n",
       "Canada            607\n",
       "Brazil            402\n",
       "Indonesia         379\n",
       "Latvia            258\n",
       "Madagascar        220\n",
       "Yemen             206\n",
       "Bhutan            189\n",
       "Swaziland         120\n",
       "Suriname           99\n",
       "Name: OuterLinks, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Sorted by U_Wikilinks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "United Kingdom    1469\n",
       "Brazil            1154\n",
       "Canada             883\n",
       "Indonesia          789\n",
       "Yemen              775\n",
       "Latvia             730\n",
       "Bhutan             536\n",
       "Suriname           518\n",
       "Madagascar         509\n",
       "Swaziland          258\n",
       "Name: U_Wikilinks, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Sorted by U_OuterLinks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "United Kingdom    610\n",
       "Canada            565\n",
       "Brazil            378\n",
       "Indonesia         375\n",
       "Latvia            241\n",
       "Madagascar        214\n",
       "Yemen             194\n",
       "Bhutan            186\n",
       "Swaziland         115\n",
       "Suriname           91\n",
       "Name: U_OuterLinks, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Sorted by PageLength\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "United Kingdom    325644\n",
       "Brazil            242077\n",
       "Canada            234879\n",
       "Yemen             207542\n",
       "Indonesia         192566\n",
       "Madagascar        167082\n",
       "Latvia            162347\n",
       "Bhutan            124736\n",
       "Suriname           87635\n",
       "Swaziland          81842\n",
       "Name: PageLength, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Sorted by Population\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Indonesia         237641326\n",
       "Brazil            210147125\n",
       "United Kingdom     63181775\n",
       "Canada             37067011\n",
       "Yemen              19685000\n",
       "Madagascar         12238914\n",
       "Latvia              1925800\n",
       "Swaziland           1093238\n",
       "Bhutan               634982\n",
       "Suriname             541638\n",
       "Name: Population, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now, select 10 countries and place them in a list. \n",
    "# These will be rows in a dataframe. \n",
    "# For each of the ten countries, \n",
    "# find the following features from parsing their wikipedia page: \n",
    "# 1. The number of internal wikilinks. \n",
    "# 2. The number of external wikilinks. \n",
    "# 3. The length of the page (in characters)\n",
    "# 4. The population of the country. \n",
    "#   - This last one will be very tricky. It's okay if you cannot get the \n",
    "#     regex working, or if you have to build multiple regexes. \n",
    "#     Please simply document this. \n",
    "\n",
    "# Print the following: \n",
    "# The rank order of each of the columns. \n",
    "# For example, for wikilinks you might print \n",
    "# (note numbrs below are not accurate)\n",
    "\n",
    "# Table 1. Number of <Wikilinks>\n",
    "# Canada        46\n",
    "# Germany       45\n",
    "# France        24\n",
    "# Netherlands   12\n",
    "# ...\n",
    "\n",
    "# answer below here\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "countries = ['United Kingdom', 'Canada', 'Swaziland', 'Indonesia', 'Suriname', 'Bhutan', 'Latvia', 'Madagascar', 'Yemen', 'Brazil']\n",
    "\n",
    "countries_df = pd.DataFrame(columns = ['Wikilinks', 'OuterLinks', 'U_Wikilinks', 'U_OuterLinks', 'PageLength', 'Population']) # initialise df\n",
    "text_to_parse = {}\n",
    "for i in countries:\n",
    "    print(i) # progress indicator\n",
    "    data = getWikiPage(i) # gets page data\n",
    "    soup = bs4.BeautifulSoup(data.decode('utf8'), \"lxml\")\n",
    "    text_to_parse[i] = soup.mediawiki.page.text # get the text to parse (and is stored in dict - not really necessary, but might be useful if we want to quickly access text later)\n",
    "\n",
    "    re_inner_links = re.compile(r'\\[\\[.*?\\]\\]') # regex as before for internal links\n",
    "    inner_links = re_inner_links.findall(text_to_parse[i]) # regex as before for internal links\n",
    "\n",
    "    re_outer_links = re.compile(r'https?://[\\w\\./?&=%]*') # regex as before for external links\n",
    "    outer_links = re_outer_links.findall(text_to_parse[i]) # regex as before for external links\n",
    "    \n",
    "    pagelength = len(soup.text) # page length  - (or len(text_to_parse), slightly different result)\n",
    "    \n",
    "    # population data - some of this data is represented as a wiki template {{UN Population|countryname}}, which is not trivial to fetch with our current approach\n",
    "    # usually/always(?) at least one of population estimate or population census have the number explicitly displayed\n",
    "    # We're not going to be fussy, and just select the first of these that has a value\n",
    "    re_population = re.compile(r'population_[a-z]*\\s*=\\s*([\\d,]*)') # regex returns the string of numbers (\\d) and commas (,) that follows \"population_[some word] = \"\n",
    "    populationlist = re_population.findall(text_to_parse[i]) # returns a list as occasionally there are 2 matches\n",
    "    population = int([s for s in populationlist if s][0].replace(',', '')) # gets the first non empty string, removes the commas, and casts as an int\n",
    "    \n",
    "    countries_df.loc[i] = [len(inner_links), len(outer_links), len(set(inner_links)), len(set(outer_links)), pagelength, population] # add the data as a row in the df\n",
    "    \n",
    "display(countries_df) # display df\n",
    "\n",
    "# displaying sorted columns:\n",
    "for i in countries_df.columns: # for each column\n",
    "    print('\\n\\nSorted by', i)\n",
    "    display(countries_df[i].sort_values(ascending=False)) # sort the df by the specified column (descending), and display\n",
    "\n",
    "\n",
    "\n",
    "# Reviewer's comments\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
